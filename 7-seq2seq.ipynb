{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee46227",
   "metadata": {},
   "source": [
    "# 7.seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ac1b9",
   "metadata": {},
   "source": [
    "## 7.1 使用语言模型生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbceffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#文本生成的实现\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "from ch06.rnnlm import Rnnlm\n",
    "from ch06.better_rnnlm import BetterRnnlm\n",
    "\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "            p = softmax(score.flatten())\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state)\n",
    "\n",
    "\n",
    "class BetterRnnlmGen(BetterRnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x).flatten()\n",
    "            p = softmax(score).flatten()\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        states = []\n",
    "        for layer in self.lstm_layers:\n",
    "            states.append((layer.h, layer.c))\n",
    "        return states\n",
    "\n",
    "    def set_state(self, states):\n",
    "        for layer, state in zip(self.lstm_layers, states):\n",
    "            layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58146995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you 'd want to hear the risk going.\n",
      " while he is n't written to make that even there on u.s. opening to any securities on real estate investment in maker in location analysis.\n",
      " no one might like traditional while the cars will carry through any stock strategy when the move is taking out the contract market and unisys business are in hurricane and crucial hard free.\n",
      " analysts tried to build special improvement to the work facility from the book questioned costs like this.\n",
      " for the job mr. sagan came a imagine between rape and marriage of\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from ch06.rnnlm_gen import RnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "model.load_params('./ch06/Rnnlm.pkl')\n",
    "\n",
    "# 设定start单词和skip单词\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "# 文本生成\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b84c65",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file: ./ch06/BetterRnnlm.pkl",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a43d34940f7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBetterRnnlmGen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ch06/BetterRnnlm.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 设定start字符和skip字符\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/zhangyunfei/deeplearning/NLP-source/common/base_model.py\u001b[0m in \u001b[0;36mload_params\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No file: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: No file: ./ch06/BetterRnnlm.pkl"
     ]
    }
   ],
   "source": [
    "# 更好的文本生成\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *\n",
    "# from rnnlm_gen import BetterRnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "\n",
    "model = BetterRnnlmGen()\n",
    "model.load_params('./ch06/BetterRnnlm.pkl')\n",
    "\n",
    "# 设定start字符和skip字符\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 文本生成\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "\n",
    "print(txt)\n",
    "\n",
    "\n",
    "model.reset_state()\n",
    "\n",
    "start_words = 'the meaning of life is'\n",
    "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
    "\n",
    "for x in start_ids[:-1]:\n",
    "    x = np.array(x).reshape(1, 1)\n",
    "    model.predict(x)\n",
    "\n",
    "word_ids = model.generate(start_ids[-1], skip_ids)\n",
    "word_ids = start_ids[:-1] + word_ids\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print('-' * 50)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca1dc7",
   "metadata": {},
   "source": [
    "## 7.2 seq2seq模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d60f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7) (45000, 5)\n",
      "(5000, 7) (5000, 5)\n",
      "[ 3  0  2  0  0 11  5]\n",
      "[ 6  0 11  7  5]\n",
      "71+118 \n",
      "_189 \n"
     ]
    }
   ],
   "source": [
    "# 加法数据集\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import sequence\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    sequence.load_data('addition.txt', seed=1984)\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "print(x_train.shape, t_train.shape)\n",
    "print(x_test.shape, t_test.shape)\n",
    "# (45000, 7) (45000, 5)\n",
    "# (5000, 7) (5000, 5)\n",
    "\n",
    "print(x_train[0])\n",
    "print(t_train[0])\n",
    "# [ 3  0  2  0  0 11  5]\n",
    "# [ 6  0 11  7  5]\n",
    "\n",
    "print(''.join([id_to_char[c] for c in x_train[0]]))\n",
    "print(''.join([id_to_char[c] for c in t_train[0]]))\n",
    "# 71+118\n",
    "# _189\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b82ea",
   "metadata": {},
   "source": [
    "## 7.3 seq2seq的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "811f7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder类\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh\n",
    "\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout\n",
    "\n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "            out = self.lstm.forward(out)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(int(sample_id))\n",
    "\n",
    "        return sampled\n",
    "\n",
    "\n",
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "\n",
    "        h = self.encoder.forward(xs)\n",
    "        score = self.decoder.forward(decoder_xs, h)\n",
    "        loss = self.softmax.forward(score, decoder_ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n",
    "\n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs)\n",
    "        sampled = self.decoder.generate(h, start_id, sample_size)\n",
    "        return sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "348395eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 2.56\n",
      "| epoch 1 |  iter 21 / 351 | time 0[s] | loss 2.52\n",
      "| epoch 1 |  iter 41 / 351 | time 1[s] | loss 2.17\n",
      "| epoch 1 |  iter 61 / 351 | time 2[s] | loss 1.96\n",
      "| epoch 1 |  iter 81 / 351 | time 3[s] | loss 1.91\n",
      "| epoch 1 |  iter 101 / 351 | time 3[s] | loss 1.87\n",
      "| epoch 1 |  iter 121 / 351 | time 4[s] | loss 1.86\n",
      "| epoch 1 |  iter 141 / 351 | time 5[s] | loss 1.84\n",
      "| epoch 1 |  iter 161 / 351 | time 6[s] | loss 1.80\n",
      "| epoch 1 |  iter 181 / 351 | time 7[s] | loss 1.78\n",
      "| epoch 1 |  iter 201 / 351 | time 7[s] | loss 1.77\n",
      "| epoch 1 |  iter 221 / 351 | time 8[s] | loss 1.77\n",
      "| epoch 1 |  iter 241 / 351 | time 9[s] | loss 1.76\n",
      "| epoch 1 |  iter 261 / 351 | time 10[s] | loss 1.75\n",
      "| epoch 1 |  iter 281 / 351 | time 11[s] | loss 1.74\n",
      "| epoch 1 |  iter 301 / 351 | time 11[s] | loss 1.74\n",
      "| epoch 1 |  iter 321 / 351 | time 12[s] | loss 1.74\n",
      "| epoch 1 |  iter 341 / 351 | time 13[s] | loss 1.73\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 703 \n",
      "---\n",
      "val acc 0.120%\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.73\n",
      "| epoch 2 |  iter 21 / 351 | time 0[s] | loss 1.72\n",
      "| epoch 2 |  iter 41 / 351 | time 1[s] | loss 1.72\n",
      "| epoch 2 |  iter 61 / 351 | time 2[s] | loss 1.72\n",
      "| epoch 2 |  iter 81 / 351 | time 3[s] | loss 1.70\n",
      "| epoch 2 |  iter 101 / 351 | time 4[s] | loss 1.70\n",
      "| epoch 2 |  iter 121 / 351 | time 5[s] | loss 1.69\n",
      "| epoch 2 |  iter 141 / 351 | time 5[s] | loss 1.68\n",
      "| epoch 2 |  iter 161 / 351 | time 6[s] | loss 1.67\n",
      "| epoch 2 |  iter 181 / 351 | time 7[s] | loss 1.66\n",
      "| epoch 2 |  iter 201 / 351 | time 8[s] | loss 1.66\n",
      "| epoch 2 |  iter 221 / 351 | time 9[s] | loss 1.65\n",
      "| epoch 2 |  iter 241 / 351 | time 9[s] | loss 1.63\n",
      "| epoch 2 |  iter 261 / 351 | time 10[s] | loss 1.62\n",
      "| epoch 2 |  iter 281 / 351 | time 11[s] | loss 1.61\n",
      "| epoch 2 |  iter 301 / 351 | time 12[s] | loss 1.60\n",
      "| epoch 2 |  iter 321 / 351 | time 13[s] | loss 1.58\n",
      "| epoch 2 |  iter 341 / 351 | time 13[s] | loss 1.56\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 690 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 470 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 700 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1444\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 700 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 370 \n",
      "---\n",
      "val acc 0.400%\n",
      "| epoch 3 |  iter 1 / 351 | time 0[s] | loss 1.52\n",
      "| epoch 3 |  iter 21 / 351 | time 0[s] | loss 1.53\n",
      "| epoch 3 |  iter 41 / 351 | time 1[s] | loss 1.51\n",
      "| epoch 3 |  iter 61 / 351 | time 2[s] | loss 1.49\n",
      "| epoch 3 |  iter 81 / 351 | time 3[s] | loss 1.47\n",
      "| epoch 3 |  iter 101 / 351 | time 4[s] | loss 1.45\n",
      "| epoch 3 |  iter 121 / 351 | time 4[s] | loss 1.44\n",
      "| epoch 3 |  iter 141 / 351 | time 5[s] | loss 1.42\n",
      "| epoch 3 |  iter 161 / 351 | time 6[s] | loss 1.40\n",
      "| epoch 3 |  iter 181 / 351 | time 7[s] | loss 1.38\n",
      "| epoch 3 |  iter 201 / 351 | time 8[s] | loss 1.37\n",
      "| epoch 3 |  iter 221 / 351 | time 8[s] | loss 1.35\n",
      "| epoch 3 |  iter 241 / 351 | time 9[s] | loss 1.33\n",
      "| epoch 3 |  iter 261 / 351 | time 10[s] | loss 1.32\n",
      "| epoch 3 |  iter 281 / 351 | time 11[s] | loss 1.30\n",
      "| epoch 3 |  iter 301 / 351 | time 12[s] | loss 1.29\n",
      "| epoch 3 |  iter 321 / 351 | time 13[s] | loss 1.28\n",
      "| epoch 3 |  iter 341 / 351 | time 14[s] | loss 1.27\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1148\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 662 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 382 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 818 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1008\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1434\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 838 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 202 \n",
      "---\n",
      "val acc 1.940%\n",
      "| epoch 4 |  iter 1 / 351 | time 0[s] | loss 1.26\n",
      "| epoch 4 |  iter 21 / 351 | time 0[s] | loss 1.25\n",
      "| epoch 4 |  iter 41 / 351 | time 1[s] | loss 1.23\n",
      "| epoch 4 |  iter 61 / 351 | time 2[s] | loss 1.22\n",
      "| epoch 4 |  iter 81 / 351 | time 3[s] | loss 1.20\n",
      "| epoch 4 |  iter 101 / 351 | time 4[s] | loss 1.19\n",
      "| epoch 4 |  iter 121 / 351 | time 5[s] | loss 1.18\n",
      "| epoch 4 |  iter 141 / 351 | time 5[s] | loss 1.17\n",
      "| epoch 4 |  iter 161 / 351 | time 6[s] | loss 1.15\n",
      "| epoch 4 |  iter 181 / 351 | time 7[s] | loss 1.13\n",
      "| epoch 4 |  iter 201 / 351 | time 8[s] | loss 1.12\n",
      "| epoch 4 |  iter 221 / 351 | time 9[s] | loss 1.11\n",
      "| epoch 4 |  iter 241 / 351 | time 10[s] | loss 1.09\n",
      "| epoch 4 |  iter 261 / 351 | time 11[s] | loss 1.08\n",
      "| epoch 4 |  iter 281 / 351 | time 12[s] | loss 1.07\n",
      "| epoch 4 |  iter 301 / 351 | time 12[s] | loss 1.07\n",
      "| epoch 4 |  iter 321 / 351 | time 13[s] | loss 1.05\n",
      "| epoch 4 |  iter 341 / 351 | time 14[s] | loss 1.03\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1196\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 896 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1010\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1496\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 868 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "val acc 5.780%\n",
      "| epoch 5 |  iter 1 / 351 | time 0[s] | loss 1.01\n",
      "| epoch 5 |  iter 21 / 351 | time 0[s] | loss 1.01\n",
      "| epoch 5 |  iter 41 / 351 | time 1[s] | loss 1.00\n",
      "| epoch 5 |  iter 61 / 351 | time 2[s] | loss 0.99\n",
      "| epoch 5 |  iter 81 / 351 | time 3[s] | loss 0.97\n",
      "| epoch 5 |  iter 101 / 351 | time 4[s] | loss 0.95\n",
      "| epoch 5 |  iter 121 / 351 | time 5[s] | loss 0.95\n",
      "| epoch 5 |  iter 141 / 351 | time 6[s] | loss 0.94\n",
      "| epoch 5 |  iter 161 / 351 | time 7[s] | loss 0.93\n",
      "| epoch 5 |  iter 181 / 351 | time 7[s] | loss 0.93\n",
      "| epoch 5 |  iter 201 / 351 | time 8[s] | loss 0.91\n",
      "| epoch 5 |  iter 221 / 351 | time 9[s] | loss 0.89\n",
      "| epoch 5 |  iter 241 / 351 | time 10[s] | loss 0.89\n",
      "| epoch 5 |  iter 261 / 351 | time 11[s] | loss 0.88\n",
      "| epoch 5 |  iter 281 / 351 | time 12[s] | loss 0.87\n",
      "| epoch 5 |  iter 301 / 351 | time 13[s] | loss 0.86\n",
      "| epoch 5 |  iter 321 / 351 | time 14[s] | loss 0.85\n",
      "| epoch 5 |  iter 341 / 351 | time 14[s] | loss 0.84\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1192\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 860 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1066\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1414\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 232 \n",
      "---\n",
      "val acc 12.460%\n",
      "| epoch 6 |  iter 1 / 351 | time 0[s] | loss 0.86\n",
      "| epoch 6 |  iter 21 / 351 | time 0[s] | loss 0.82\n",
      "| epoch 6 |  iter 41 / 351 | time 1[s] | loss 0.82\n",
      "| epoch 6 |  iter 61 / 351 | time 2[s] | loss 0.81\n",
      "| epoch 6 |  iter 81 / 351 | time 3[s] | loss 0.80\n",
      "| epoch 6 |  iter 101 / 351 | time 4[s] | loss 0.80\n",
      "| epoch 6 |  iter 121 / 351 | time 5[s] | loss 0.79\n",
      "| epoch 6 |  iter 141 / 351 | time 6[s] | loss 0.78\n",
      "| epoch 6 |  iter 161 / 351 | time 7[s] | loss 0.77\n",
      "| epoch 6 |  iter 181 / 351 | time 7[s] | loss 0.77\n",
      "| epoch 6 |  iter 201 / 351 | time 8[s] | loss 0.78\n",
      "| epoch 6 |  iter 221 / 351 | time 9[s] | loss 0.76\n",
      "| epoch 6 |  iter 241 / 351 | time 10[s] | loss 0.75\n",
      "| epoch 6 |  iter 261 / 351 | time 11[s] | loss 0.74\n",
      "| epoch 6 |  iter 281 / 351 | time 12[s] | loss 0.73\n",
      "| epoch 6 |  iter 301 / 351 | time 12[s] | loss 0.73\n",
      "| epoch 6 |  iter 321 / 351 | time 13[s] | loss 0.72\n",
      "| epoch 6 |  iter 341 / 351 | time 14[s] | loss 0.72\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1141\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 661 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 851 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1061\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1391\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 234 \n",
      "---\n",
      "val acc 14.260%\n",
      "| epoch 7 |  iter 1 / 351 | time 0[s] | loss 0.71\n",
      "| epoch 7 |  iter 21 / 351 | time 0[s] | loss 0.71\n",
      "| epoch 7 |  iter 41 / 351 | time 1[s] | loss 0.70\n",
      "| epoch 7 |  iter 61 / 351 | time 2[s] | loss 0.70\n",
      "| epoch 7 |  iter 81 / 351 | time 3[s] | loss 0.68\n",
      "| epoch 7 |  iter 101 / 351 | time 4[s] | loss 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 7 |  iter 121 / 351 | time 5[s] | loss 0.67\n",
      "| epoch 7 |  iter 141 / 351 | time 6[s] | loss 0.67\n",
      "| epoch 7 |  iter 161 / 351 | time 7[s] | loss 0.67\n",
      "| epoch 7 |  iter 181 / 351 | time 7[s] | loss 0.66\n",
      "| epoch 7 |  iter 201 / 351 | time 8[s] | loss 0.66\n",
      "| epoch 7 |  iter 221 / 351 | time 9[s] | loss 0.66\n",
      "| epoch 7 |  iter 241 / 351 | time 10[s] | loss 0.64\n",
      "| epoch 7 |  iter 261 / 351 | time 11[s] | loss 0.65\n",
      "| epoch 7 |  iter 281 / 351 | time 12[s] | loss 0.64\n",
      "| epoch 7 |  iter 301 / 351 | time 13[s] | loss 0.63\n",
      "| epoch 7 |  iter 321 / 351 | time 14[s] | loss 0.63\n",
      "| epoch 7 |  iter 341 / 351 | time 14[s] | loss 0.62\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1142\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1144\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1431\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "val acc 17.500%\n",
      "| epoch 8 |  iter 1 / 351 | time 0[s] | loss 0.66\n",
      "| epoch 8 |  iter 21 / 351 | time 0[s] | loss 0.61\n",
      "| epoch 8 |  iter 41 / 351 | time 1[s] | loss 0.62\n",
      "| epoch 8 |  iter 61 / 351 | time 2[s] | loss 0.61\n",
      "| epoch 8 |  iter 81 / 351 | time 3[s] | loss 0.61\n",
      "| epoch 8 |  iter 101 / 351 | time 4[s] | loss 0.61\n",
      "| epoch 8 |  iter 121 / 351 | time 5[s] | loss 0.60\n",
      "| epoch 8 |  iter 141 / 351 | time 6[s] | loss 0.60\n",
      "| epoch 8 |  iter 161 / 351 | time 7[s] | loss 0.59\n",
      "| epoch 8 |  iter 181 / 351 | time 7[s] | loss 0.58\n",
      "| epoch 8 |  iter 201 / 351 | time 8[s] | loss 0.59\n",
      "| epoch 8 |  iter 221 / 351 | time 9[s] | loss 0.60\n",
      "| epoch 8 |  iter 241 / 351 | time 10[s] | loss 0.59\n",
      "| epoch 8 |  iter 261 / 351 | time 11[s] | loss 0.58\n",
      "| epoch 8 |  iter 281 / 351 | time 12[s] | loss 0.59\n",
      "| epoch 8 |  iter 301 / 351 | time 13[s] | loss 0.58\n",
      "| epoch 8 |  iter 321 / 351 | time 14[s] | loss 0.57\n",
      "| epoch 8 |  iter 341 / 351 | time 14[s] | loss 0.57\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1134\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 759 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1431\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 238 \n",
      "---\n",
      "val acc 23.080%\n",
      "| epoch 9 |  iter 1 / 351 | time 0[s] | loss 0.55\n",
      "| epoch 9 |  iter 21 / 351 | time 0[s] | loss 0.56\n",
      "| epoch 9 |  iter 41 / 351 | time 1[s] | loss 0.56\n",
      "| epoch 9 |  iter 61 / 351 | time 2[s] | loss 0.55\n",
      "| epoch 9 |  iter 81 / 351 | time 3[s] | loss 0.54\n",
      "| epoch 9 |  iter 101 / 351 | time 4[s] | loss 0.55\n",
      "| epoch 9 |  iter 121 / 351 | time 5[s] | loss 0.55\n",
      "| epoch 9 |  iter 141 / 351 | time 6[s] | loss 0.54\n",
      "| epoch 9 |  iter 161 / 351 | time 6[s] | loss 0.55\n",
      "| epoch 9 |  iter 181 / 351 | time 7[s] | loss 0.53\n",
      "| epoch 9 |  iter 201 / 351 | time 8[s] | loss 0.54\n",
      "| epoch 9 |  iter 221 / 351 | time 9[s] | loss 0.54\n",
      "| epoch 9 |  iter 241 / 351 | time 10[s] | loss 0.53\n",
      "| epoch 9 |  iter 261 / 351 | time 11[s] | loss 0.53\n",
      "| epoch 9 |  iter 281 / 351 | time 12[s] | loss 0.54\n",
      "| epoch 9 |  iter 301 / 351 | time 12[s] | loss 0.54\n",
      "| epoch 9 |  iter 321 / 351 | time 13[s] | loss 0.53\n",
      "| epoch 9 |  iter 341 / 351 | time 14[s] | loss 0.53\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1142\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 664 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 854 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1428\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 238 \n",
      "---\n",
      "val acc 26.520%\n",
      "| epoch 10 |  iter 1 / 351 | time 0[s] | loss 0.50\n",
      "| epoch 10 |  iter 21 / 351 | time 0[s] | loss 0.51\n",
      "| epoch 10 |  iter 41 / 351 | time 1[s] | loss 0.52\n",
      "| epoch 10 |  iter 61 / 351 | time 2[s] | loss 0.55\n",
      "| epoch 10 |  iter 81 / 351 | time 3[s] | loss 0.52\n",
      "| epoch 10 |  iter 101 / 351 | time 4[s] | loss 0.51\n",
      "| epoch 10 |  iter 121 / 351 | time 5[s] | loss 0.50\n",
      "| epoch 10 |  iter 141 / 351 | time 6[s] | loss 0.51\n",
      "| epoch 10 |  iter 161 / 351 | time 7[s] | loss 0.52\n",
      "| epoch 10 |  iter 181 / 351 | time 7[s] | loss 0.53\n",
      "| epoch 10 |  iter 201 / 351 | time 8[s] | loss 0.50\n",
      "| epoch 10 |  iter 221 / 351 | time 9[s] | loss 0.50\n",
      "| epoch 10 |  iter 241 / 351 | time 10[s] | loss 0.50\n",
      "| epoch 10 |  iter 261 / 351 | time 11[s] | loss 0.50\n",
      "| epoch 10 |  iter 281 / 351 | time 12[s] | loss 0.49\n",
      "| epoch 10 |  iter 301 / 351 | time 13[s] | loss 0.48\n",
      "| epoch 10 |  iter 321 / 351 | time 13[s] | loss 0.48\n",
      "| epoch 10 |  iter 341 / 351 | time 14[s] | loss 0.48\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 664 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1054\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1431\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "val acc 29.820%\n",
      "| epoch 11 |  iter 1 / 351 | time 0[s] | loss 0.47\n",
      "| epoch 11 |  iter 21 / 351 | time 0[s] | loss 0.48\n",
      "| epoch 11 |  iter 41 / 351 | time 1[s] | loss 0.48\n",
      "| epoch 11 |  iter 61 / 351 | time 2[s] | loss 0.48\n",
      "| epoch 11 |  iter 81 / 351 | time 3[s] | loss 0.47\n",
      "| epoch 11 |  iter 101 / 351 | time 4[s] | loss 0.47\n",
      "| epoch 11 |  iter 121 / 351 | time 5[s] | loss 0.47\n",
      "| epoch 11 |  iter 141 / 351 | time 5[s] | loss 0.47\n",
      "| epoch 11 |  iter 161 / 351 | time 6[s] | loss 0.48\n",
      "| epoch 11 |  iter 181 / 351 | time 7[s] | loss 0.48\n",
      "| epoch 11 |  iter 201 / 351 | time 8[s] | loss 0.47\n",
      "| epoch 11 |  iter 221 / 351 | time 9[s] | loss 0.47\n",
      "| epoch 11 |  iter 241 / 351 | time 10[s] | loss 0.46\n",
      "| epoch 11 |  iter 261 / 351 | time 10[s] | loss 0.46\n",
      "| epoch 11 |  iter 281 / 351 | time 11[s] | loss 0.46\n",
      "| epoch 11 |  iter 301 / 351 | time 12[s] | loss 0.48\n",
      "| epoch 11 |  iter 321 / 351 | time 13[s] | loss 0.45\n",
      "| epoch 11 |  iter 341 / 351 | time 14[s] | loss 0.45\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1426\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 238 \n",
      "---\n",
      "val acc 28.480%\n",
      "| epoch 12 |  iter 1 / 351 | time 0[s] | loss 0.46\n",
      "| epoch 12 |  iter 21 / 351 | time 0[s] | loss 0.45\n",
      "| epoch 12 |  iter 41 / 351 | time 1[s] | loss 0.45\n",
      "| epoch 12 |  iter 61 / 351 | time 2[s] | loss 0.46\n",
      "| epoch 12 |  iter 81 / 351 | time 3[s] | loss 0.45\n",
      "| epoch 12 |  iter 101 / 351 | time 4[s] | loss 0.46\n",
      "| epoch 12 |  iter 121 / 351 | time 4[s] | loss 0.46\n",
      "| epoch 12 |  iter 141 / 351 | time 5[s] | loss 0.46\n",
      "| epoch 12 |  iter 161 / 351 | time 6[s] | loss 0.45\n",
      "| epoch 12 |  iter 181 / 351 | time 7[s] | loss 0.44\n",
      "| epoch 12 |  iter 201 / 351 | time 8[s] | loss 0.45\n",
      "| epoch 12 |  iter 221 / 351 | time 9[s] | loss 0.44\n",
      "| epoch 12 |  iter 241 / 351 | time 9[s] | loss 0.43\n",
      "| epoch 12 |  iter 261 / 351 | time 10[s] | loss 0.43\n",
      "| epoch 12 |  iter 281 / 351 | time 11[s] | loss 0.44\n",
      "| epoch 12 |  iter 301 / 351 | time 12[s] | loss 0.45\n",
      "| epoch 12 |  iter 321 / 351 | time 13[s] | loss 0.44\n",
      "| epoch 12 |  iter 341 / 351 | time 13[s] | loss 0.43\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1051\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1428\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "val acc 36.640%\n",
      "| epoch 13 |  iter 1 / 351 | time 0[s] | loss 0.41\n",
      "| epoch 13 |  iter 21 / 351 | time 0[s] | loss 0.43\n",
      "| epoch 13 |  iter 41 / 351 | time 1[s] | loss 0.42\n",
      "| epoch 13 |  iter 61 / 351 | time 2[s] | loss 0.42\n",
      "| epoch 13 |  iter 81 / 351 | time 3[s] | loss 0.42\n",
      "| epoch 13 |  iter 101 / 351 | time 4[s] | loss 0.44\n",
      "| epoch 13 |  iter 121 / 351 | time 5[s] | loss 0.43\n",
      "| epoch 13 |  iter 141 / 351 | time 5[s] | loss 0.41\n",
      "| epoch 13 |  iter 161 / 351 | time 6[s] | loss 0.42\n",
      "| epoch 13 |  iter 181 / 351 | time 7[s] | loss 0.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 13 |  iter 201 / 351 | time 8[s] | loss 0.42\n",
      "| epoch 13 |  iter 221 / 351 | time 9[s] | loss 0.43\n",
      "| epoch 13 |  iter 241 / 351 | time 10[s] | loss 0.43\n",
      "| epoch 13 |  iter 261 / 351 | time 10[s] | loss 0.41\n",
      "| epoch 13 |  iter 281 / 351 | time 11[s] | loss 0.42\n",
      "| epoch 13 |  iter 301 / 351 | time 12[s] | loss 0.41\n",
      "| epoch 13 |  iter 321 / 351 | time 13[s] | loss 0.43\n",
      "| epoch 13 |  iter 341 / 351 | time 14[s] | loss 0.40\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 424 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1054\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "val acc 39.420%\n",
      "| epoch 14 |  iter 1 / 351 | time 0[s] | loss 0.41\n",
      "| epoch 14 |  iter 21 / 351 | time 0[s] | loss 0.41\n",
      "| epoch 14 |  iter 41 / 351 | time 1[s] | loss 0.41\n",
      "| epoch 14 |  iter 61 / 351 | time 2[s] | loss 0.40\n",
      "| epoch 14 |  iter 81 / 351 | time 3[s] | loss 0.40\n",
      "| epoch 14 |  iter 101 / 351 | time 4[s] | loss 0.41\n",
      "| epoch 14 |  iter 121 / 351 | time 5[s] | loss 0.39\n",
      "| epoch 14 |  iter 141 / 351 | time 6[s] | loss 0.39\n",
      "| epoch 14 |  iter 161 / 351 | time 7[s] | loss 0.38\n",
      "| epoch 14 |  iter 181 / 351 | time 7[s] | loss 0.38\n",
      "| epoch 14 |  iter 201 / 351 | time 8[s] | loss 0.38\n",
      "| epoch 14 |  iter 221 / 351 | time 9[s] | loss 0.38\n",
      "| epoch 14 |  iter 241 / 351 | time 10[s] | loss 0.39\n",
      "| epoch 14 |  iter 261 / 351 | time 11[s] | loss 0.40\n",
      "| epoch 14 |  iter 281 / 351 | time 12[s] | loss 0.41\n",
      "| epoch 14 |  iter 301 / 351 | time 13[s] | loss 0.39\n",
      "| epoch 14 |  iter 321 / 351 | time 14[s] | loss 0.39\n",
      "| epoch 14 |  iter 341 / 351 | time 15[s] | loss 0.39\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1137\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 858 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1426\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "val acc 36.680%\n",
      "| epoch 15 |  iter 1 / 351 | time 0[s] | loss 0.38\n",
      "| epoch 15 |  iter 21 / 351 | time 0[s] | loss 0.39\n",
      "| epoch 15 |  iter 41 / 351 | time 1[s] | loss 0.39\n",
      "| epoch 15 |  iter 61 / 351 | time 2[s] | loss 0.38\n",
      "| epoch 15 |  iter 81 / 351 | time 3[s] | loss 0.38\n",
      "| epoch 15 |  iter 101 / 351 | time 4[s] | loss 0.38\n",
      "| epoch 15 |  iter 121 / 351 | time 5[s] | loss 0.38\n",
      "| epoch 15 |  iter 141 / 351 | time 5[s] | loss 0.38\n",
      "| epoch 15 |  iter 161 / 351 | time 6[s] | loss 0.38\n",
      "| epoch 15 |  iter 181 / 351 | time 7[s] | loss 0.38\n",
      "| epoch 15 |  iter 201 / 351 | time 8[s] | loss 0.38\n",
      "| epoch 15 |  iter 221 / 351 | time 9[s] | loss 0.39\n",
      "| epoch 15 |  iter 241 / 351 | time 10[s] | loss 0.38\n",
      "| epoch 15 |  iter 261 / 351 | time 11[s] | loss 0.37\n",
      "| epoch 15 |  iter 281 / 351 | time 12[s] | loss 0.37\n",
      "| epoch 15 |  iter 301 / 351 | time 12[s] | loss 0.39\n",
      "| epoch 15 |  iter 321 / 351 | time 13[s] | loss 0.39\n",
      "| epoch 15 |  iter 341 / 351 | time 14[s] | loss 0.37\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1137\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 420 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1052\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1431\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "val acc 41.100%\n",
      "| epoch 16 |  iter 1 / 351 | time 0[s] | loss 0.36\n",
      "| epoch 16 |  iter 21 / 351 | time 0[s] | loss 0.36\n",
      "| epoch 16 |  iter 41 / 351 | time 1[s] | loss 0.36\n",
      "| epoch 16 |  iter 61 / 351 | time 2[s] | loss 0.36\n",
      "| epoch 16 |  iter 81 / 351 | time 3[s] | loss 0.37\n",
      "| epoch 16 |  iter 101 / 351 | time 4[s] | loss 0.36\n",
      "| epoch 16 |  iter 121 / 351 | time 5[s] | loss 0.37\n",
      "| epoch 16 |  iter 141 / 351 | time 6[s] | loss 0.36\n",
      "| epoch 16 |  iter 161 / 351 | time 7[s] | loss 0.37\n",
      "| epoch 16 |  iter 181 / 351 | time 8[s] | loss 0.36\n",
      "| epoch 16 |  iter 201 / 351 | time 9[s] | loss 0.38\n",
      "| epoch 16 |  iter 221 / 351 | time 9[s] | loss 0.38\n",
      "| epoch 16 |  iter 241 / 351 | time 10[s] | loss 0.36\n",
      "| epoch 16 |  iter 261 / 351 | time 11[s] | loss 0.35\n",
      "| epoch 16 |  iter 281 / 351 | time 12[s] | loss 0.35\n",
      "| epoch 16 |  iter 301 / 351 | time 13[s] | loss 0.35\n",
      "| epoch 16 |  iter 321 / 351 | time 14[s] | loss 0.35\n",
      "| epoch 16 |  iter 341 / 351 | time 15[s] | loss 0.37\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1142\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 858 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1054\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1430\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "val acc 42.700%\n",
      "| epoch 17 |  iter 1 / 351 | time 0[s] | loss 0.34\n",
      "| epoch 17 |  iter 21 / 351 | time 0[s] | loss 0.36\n",
      "| epoch 17 |  iter 41 / 351 | time 1[s] | loss 0.36\n",
      "| epoch 17 |  iter 61 / 351 | time 2[s] | loss 0.35\n",
      "| epoch 17 |  iter 81 / 351 | time 3[s] | loss 0.36\n",
      "| epoch 17 |  iter 101 / 351 | time 4[s] | loss 0.34\n",
      "| epoch 17 |  iter 121 / 351 | time 5[s] | loss 0.34\n",
      "| epoch 17 |  iter 141 / 351 | time 5[s] | loss 0.34\n",
      "| epoch 17 |  iter 161 / 351 | time 6[s] | loss 0.34\n",
      "| epoch 17 |  iter 181 / 351 | time 7[s] | loss 0.35\n",
      "| epoch 17 |  iter 201 / 351 | time 8[s] | loss 0.35\n",
      "| epoch 17 |  iter 221 / 351 | time 9[s] | loss 0.34\n",
      "| epoch 17 |  iter 241 / 351 | time 10[s] | loss 0.35\n",
      "| epoch 17 |  iter 261 / 351 | time 11[s] | loss 0.36\n",
      "| epoch 17 |  iter 281 / 351 | time 11[s] | loss 0.37\n",
      "| epoch 17 |  iter 301 / 351 | time 12[s] | loss 0.37\n",
      "| epoch 17 |  iter 321 / 351 | time 13[s] | loss 0.37\n",
      "| epoch 17 |  iter 341 / 351 | time 14[s] | loss 0.36\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1051\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 42.860%\n",
      "| epoch 18 |  iter 1 / 351 | time 0[s] | loss 0.34\n",
      "| epoch 18 |  iter 21 / 351 | time 0[s] | loss 0.36\n",
      "| epoch 18 |  iter 41 / 351 | time 1[s] | loss 0.35\n",
      "| epoch 18 |  iter 61 / 351 | time 2[s] | loss 0.35\n",
      "| epoch 18 |  iter 81 / 351 | time 3[s] | loss 0.34\n",
      "| epoch 18 |  iter 101 / 351 | time 4[s] | loss 0.34\n",
      "| epoch 18 |  iter 121 / 351 | time 5[s] | loss 0.33\n",
      "| epoch 18 |  iter 141 / 351 | time 5[s] | loss 0.33\n",
      "| epoch 18 |  iter 161 / 351 | time 6[s] | loss 0.34\n",
      "| epoch 18 |  iter 181 / 351 | time 7[s] | loss 0.33\n",
      "| epoch 18 |  iter 201 / 351 | time 8[s] | loss 0.33\n",
      "| epoch 18 |  iter 221 / 351 | time 9[s] | loss 0.33\n",
      "| epoch 18 |  iter 241 / 351 | time 10[s] | loss 0.33\n",
      "| epoch 18 |  iter 261 / 351 | time 11[s] | loss 0.33\n",
      "| epoch 18 |  iter 281 / 351 | time 11[s] | loss 0.33\n",
      "| epoch 18 |  iter 301 / 351 | time 12[s] | loss 0.33\n",
      "| epoch 18 |  iter 321 / 351 | time 13[s] | loss 0.35\n",
      "| epoch 18 |  iter 341 / 351 | time 14[s] | loss 0.35\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1052\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1425\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "val acc 40.640%\n",
      "| epoch 19 |  iter 1 / 351 | time 0[s] | loss 0.34\n",
      "| epoch 19 |  iter 21 / 351 | time 0[s] | loss 0.34\n",
      "| epoch 19 |  iter 41 / 351 | time 1[s] | loss 0.34\n",
      "| epoch 19 |  iter 61 / 351 | time 2[s] | loss 0.34\n",
      "| epoch 19 |  iter 81 / 351 | time 3[s] | loss 0.34\n",
      "| epoch 19 |  iter 101 / 351 | time 4[s] | loss 0.32\n",
      "| epoch 19 |  iter 121 / 351 | time 5[s] | loss 0.31\n",
      "| epoch 19 |  iter 141 / 351 | time 6[s] | loss 0.33\n",
      "| epoch 19 |  iter 161 / 351 | time 7[s] | loss 0.31\n",
      "| epoch 19 |  iter 181 / 351 | time 7[s] | loss 0.30\n",
      "| epoch 19 |  iter 201 / 351 | time 8[s] | loss 0.31\n",
      "| epoch 19 |  iter 221 / 351 | time 9[s] | loss 0.31\n",
      "| epoch 19 |  iter 241 / 351 | time 10[s] | loss 0.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 19 |  iter 261 / 351 | time 11[s] | loss 0.33\n",
      "| epoch 19 |  iter 281 / 351 | time 12[s] | loss 0.32\n",
      "| epoch 19 |  iter 301 / 351 | time 13[s] | loss 0.32\n",
      "| epoch 19 |  iter 321 / 351 | time 14[s] | loss 0.33\n",
      "| epoch 19 |  iter 341 / 351 | time 14[s] | loss 0.33\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 858 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1052\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1430\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 238 \n",
      "---\n",
      "val acc 47.540%\n",
      "| epoch 20 |  iter 1 / 351 | time 0[s] | loss 0.32\n",
      "| epoch 20 |  iter 21 / 351 | time 0[s] | loss 0.35\n",
      "| epoch 20 |  iter 41 / 351 | time 1[s] | loss 0.33\n",
      "| epoch 20 |  iter 61 / 351 | time 2[s] | loss 0.33\n",
      "| epoch 20 |  iter 81 / 351 | time 3[s] | loss 0.31\n",
      "| epoch 20 |  iter 101 / 351 | time 4[s] | loss 0.31\n",
      "| epoch 20 |  iter 121 / 351 | time 5[s] | loss 0.33\n",
      "| epoch 20 |  iter 141 / 351 | time 6[s] | loss 0.32\n",
      "| epoch 20 |  iter 161 / 351 | time 7[s] | loss 0.33\n",
      "| epoch 20 |  iter 181 / 351 | time 7[s] | loss 0.31\n",
      "| epoch 20 |  iter 201 / 351 | time 8[s] | loss 0.30\n",
      "| epoch 20 |  iter 221 / 351 | time 9[s] | loss 0.32\n",
      "| epoch 20 |  iter 241 / 351 | time 10[s] | loss 0.33\n",
      "| epoch 20 |  iter 261 / 351 | time 11[s] | loss 0.35\n",
      "| epoch 20 |  iter 281 / 351 | time 12[s] | loss 0.36\n",
      "| epoch 20 |  iter 301 / 351 | time 13[s] | loss 0.34\n",
      "| epoch 20 |  iter 321 / 351 | time 13[s] | loss 0.32\n",
      "| epoch 20 |  iter 341 / 351 | time 14[s] | loss 0.32\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1051\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[92m☑\u001b[0m 1427\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 49.880%\n",
      "| epoch 21 |  iter 1 / 351 | time 0[s] | loss 0.30\n",
      "| epoch 21 |  iter 21 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 21 |  iter 41 / 351 | time 1[s] | loss 0.30\n",
      "| epoch 21 |  iter 61 / 351 | time 2[s] | loss 0.30\n",
      "| epoch 21 |  iter 81 / 351 | time 3[s] | loss 0.32\n",
      "| epoch 21 |  iter 101 / 351 | time 4[s] | loss 0.32\n",
      "| epoch 21 |  iter 121 / 351 | time 5[s] | loss 0.31\n",
      "| epoch 21 |  iter 141 / 351 | time 6[s] | loss 0.30\n",
      "| epoch 21 |  iter 161 / 351 | time 7[s] | loss 0.31\n",
      "| epoch 21 |  iter 181 / 351 | time 8[s] | loss 0.31\n",
      "| epoch 21 |  iter 201 / 351 | time 9[s] | loss 0.31\n",
      "| epoch 21 |  iter 221 / 351 | time 9[s] | loss 0.32\n",
      "| epoch 21 |  iter 241 / 351 | time 10[s] | loss 0.31\n",
      "| epoch 21 |  iter 261 / 351 | time 11[s] | loss 0.29\n",
      "| epoch 21 |  iter 281 / 351 | time 12[s] | loss 0.30\n",
      "| epoch 21 |  iter 301 / 351 | time 13[s] | loss 0.29\n",
      "| epoch 21 |  iter 321 / 351 | time 14[s] | loss 0.29\n",
      "| epoch 21 |  iter 341 / 351 | time 15[s] | loss 0.29\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1052\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1428\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 51.000%\n",
      "| epoch 22 |  iter 1 / 351 | time 0[s] | loss 0.32\n",
      "| epoch 22 |  iter 21 / 351 | time 0[s] | loss 0.29\n",
      "| epoch 22 |  iter 41 / 351 | time 1[s] | loss 0.28\n",
      "| epoch 22 |  iter 61 / 351 | time 2[s] | loss 0.29\n",
      "| epoch 22 |  iter 81 / 351 | time 3[s] | loss 0.29\n",
      "| epoch 22 |  iter 101 / 351 | time 4[s] | loss 0.28\n",
      "| epoch 22 |  iter 121 / 351 | time 5[s] | loss 0.29\n",
      "| epoch 22 |  iter 141 / 351 | time 6[s] | loss 0.31\n",
      "| epoch 22 |  iter 161 / 351 | time 6[s] | loss 0.31\n",
      "| epoch 22 |  iter 181 / 351 | time 7[s] | loss 0.30\n",
      "| epoch 22 |  iter 201 / 351 | time 8[s] | loss 0.28\n",
      "| epoch 22 |  iter 221 / 351 | time 9[s] | loss 0.32\n",
      "| epoch 22 |  iter 241 / 351 | time 10[s] | loss 0.33\n",
      "| epoch 22 |  iter 261 / 351 | time 11[s] | loss 0.32\n",
      "| epoch 22 |  iter 281 / 351 | time 11[s] | loss 0.31\n",
      "| epoch 22 |  iter 301 / 351 | time 12[s] | loss 0.30\n",
      "| epoch 22 |  iter 321 / 351 | time 13[s] | loss 0.29\n",
      "| epoch 22 |  iter 341 / 351 | time 14[s] | loss 0.31\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1430\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 238 \n",
      "---\n",
      "val acc 47.700%\n",
      "| epoch 23 |  iter 1 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 23 |  iter 21 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 23 |  iter 41 / 351 | time 1[s] | loss 0.28\n",
      "| epoch 23 |  iter 61 / 351 | time 2[s] | loss 0.28\n",
      "| epoch 23 |  iter 81 / 351 | time 3[s] | loss 0.29\n",
      "| epoch 23 |  iter 101 / 351 | time 4[s] | loss 0.27\n",
      "| epoch 23 |  iter 121 / 351 | time 5[s] | loss 0.28\n",
      "| epoch 23 |  iter 141 / 351 | time 6[s] | loss 0.28\n",
      "| epoch 23 |  iter 161 / 351 | time 7[s] | loss 0.30\n",
      "| epoch 23 |  iter 181 / 351 | time 7[s] | loss 0.30\n",
      "| epoch 23 |  iter 201 / 351 | time 8[s] | loss 0.29\n",
      "| epoch 23 |  iter 221 / 351 | time 9[s] | loss 0.29\n",
      "| epoch 23 |  iter 241 / 351 | time 10[s] | loss 0.28\n",
      "| epoch 23 |  iter 261 / 351 | time 11[s] | loss 0.28\n",
      "| epoch 23 |  iter 281 / 351 | time 12[s] | loss 0.30\n",
      "| epoch 23 |  iter 301 / 351 | time 13[s] | loss 0.29\n",
      "| epoch 23 |  iter 321 / 351 | time 13[s] | loss 0.29\n",
      "| epoch 23 |  iter 341 / 351 | time 14[s] | loss 0.28\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1142\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 858 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1429\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 238 \n",
      "---\n",
      "val acc 45.100%\n",
      "| epoch 24 |  iter 1 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 24 |  iter 21 / 351 | time 0[s] | loss 0.29\n",
      "| epoch 24 |  iter 41 / 351 | time 1[s] | loss 0.28\n",
      "| epoch 24 |  iter 61 / 351 | time 2[s] | loss 0.29\n",
      "| epoch 24 |  iter 81 / 351 | time 3[s] | loss 0.30\n",
      "| epoch 24 |  iter 101 / 351 | time 4[s] | loss 0.29\n",
      "| epoch 24 |  iter 121 / 351 | time 5[s] | loss 0.29\n",
      "| epoch 24 |  iter 141 / 351 | time 6[s] | loss 0.29\n",
      "| epoch 24 |  iter 161 / 351 | time 7[s] | loss 0.28\n",
      "| epoch 24 |  iter 181 / 351 | time 8[s] | loss 0.29\n",
      "| epoch 24 |  iter 201 / 351 | time 8[s] | loss 0.28\n",
      "| epoch 24 |  iter 221 / 351 | time 9[s] | loss 0.28\n",
      "| epoch 24 |  iter 241 / 351 | time 10[s] | loss 0.29\n",
      "| epoch 24 |  iter 261 / 351 | time 11[s] | loss 0.29\n",
      "| epoch 24 |  iter 281 / 351 | time 12[s] | loss 0.29\n",
      "| epoch 24 |  iter 301 / 351 | time 13[s] | loss 0.28\n",
      "| epoch 24 |  iter 321 / 351 | time 14[s] | loss 0.27\n",
      "| epoch 24 |  iter 341 / 351 | time 15[s] | loss 0.29\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1054\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1428\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "val acc 51.820%\n",
      "| epoch 25 |  iter 1 / 351 | time 0[s] | loss 0.29\n",
      "| epoch 25 |  iter 21 / 351 | time 0[s] | loss 0.29\n",
      "| epoch 25 |  iter 41 / 351 | time 1[s] | loss 0.28\n",
      "| epoch 25 |  iter 61 / 351 | time 2[s] | loss 0.26\n",
      "| epoch 25 |  iter 81 / 351 | time 3[s] | loss 0.26\n",
      "| epoch 25 |  iter 101 / 351 | time 4[s] | loss 0.27\n",
      "| epoch 25 |  iter 121 / 351 | time 5[s] | loss 0.29\n",
      "| epoch 25 |  iter 141 / 351 | time 6[s] | loss 0.28\n",
      "| epoch 25 |  iter 161 / 351 | time 6[s] | loss 0.28\n",
      "| epoch 25 |  iter 181 / 351 | time 7[s] | loss 0.28\n",
      "| epoch 25 |  iter 201 / 351 | time 8[s] | loss 0.27\n",
      "| epoch 25 |  iter 221 / 351 | time 9[s] | loss 0.29\n",
      "| epoch 25 |  iter 241 / 351 | time 10[s] | loss 0.27\n",
      "| epoch 25 |  iter 261 / 351 | time 11[s] | loss 0.28\n",
      "| epoch 25 |  iter 281 / 351 | time 12[s] | loss 0.28\n",
      "| epoch 25 |  iter 301 / 351 | time 12[s] | loss 0.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 25 |  iter 321 / 351 | time 13[s] | loss 0.28\n",
      "| epoch 25 |  iter 341 / 351 | time 14[s] | loss 0.28\n",
      "Q   58+77\n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 461+579\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q  48+285\n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q   551+8\n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q  55+763\n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 752+006\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 292+167\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1052\n",
      "---\n",
      "Q 795+038\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1426\n",
      "---\n",
      "Q  838+62\n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q  39+341\n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 54.120%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "# from seq2seq import Seq2seq\n",
    "from ch07.peeky_seq2seq import PeekySeq2seq\n",
    "\n",
    "\n",
    "# 读入数据集\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "x_train, x_test = x_train[:,::-1], x_test[:,::-1]\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# Reverse input? =================================================\n",
    "is_reverse = False  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================\n",
    "\n",
    "# 设定超参数\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 25\n",
    "max_grad = 5.0\n",
    "\n",
    "# Normal or Peeky? ==============================================\n",
    "model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "\n",
    "# 绘制图形\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e32721",
   "metadata": {},
   "source": [
    "## 7.4 seq2seq的改进"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3103809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 反转输入数据（reverse）\n",
    "## 信息泄漏（Peeky）\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from ch07.seq2seq import Seq2seq, Encoder\n",
    "\n",
    "\n",
    "class PeekyDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(H + D, 4 * H) / np.sqrt(H + D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H + H, V) / np.sqrt(H + H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        N, T = xs.shape\n",
    "        N, H = h.shape\n",
    "\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        hs = np.repeat(h, T, axis=0).reshape(N, T, H)\n",
    "        out = np.concatenate((hs, out), axis=2)\n",
    "\n",
    "        out = self.lstm.forward(out)\n",
    "        out = np.concatenate((hs, out), axis=2)\n",
    "\n",
    "        score = self.affine.forward(out)\n",
    "        self.cache = H\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        H = self.cache\n",
    "\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout, dhs0 = dout[:, :, H:], dout[:, :, :H]\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dembed, dhs1 = dout[:, :, H:], dout[:, :, :H]\n",
    "        self.embed.backward(dembed)\n",
    "\n",
    "        dhs = dhs0 + dhs1\n",
    "        dh = self.lstm.dh + np.sum(dhs, axis=1)\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        char_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        H = h.shape[1]\n",
    "        peeky_h = h.reshape(1, 1, H)\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([char_id]).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "\n",
    "            out = np.concatenate((peeky_h, out), axis=2)\n",
    "            out = self.lstm.forward(out)\n",
    "            out = np.concatenate((peeky_h, out), axis=2)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            char_id = np.argmax(score.flatten())\n",
    "            sampled.append(char_id)\n",
    "\n",
    "        return sampled\n",
    "\n",
    "\n",
    "class PeekySeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = PeekyDecoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e110cc",
   "metadata": {},
   "source": [
    "## 7.5 seq2seq的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e80eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq的应用\n",
    "1.聊天机器人\n",
    "2.算法学习\n",
    "3.自动图像描述"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
